{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c6a9c140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stoi={'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "itos={0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "32033 words\n",
      "228146  input letters  tensor([ 0,  5, 13, 13,  1])\n",
      "228146 labels tensor([ 5, 13, 13,  1,  0])\n"
     ]
    }
   ],
   "source": [
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = ['.', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "symbol_count = len(chars)\n",
    "stoi = dict([(chars[x], x) for x in range(len(chars))])\n",
    "itos = dict([(x, chars[x]) for x in range(len(chars))])\n",
    "\n",
    "xs, ys = [], []\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for c1,c2 in zip(chs, chs[1:]):\n",
    "        ix1 = stoi[c1]\n",
    "        ix2 = stoi[c2]\n",
    "        xs.append(ix1)\n",
    "        ys.append(ix2)\n",
    "        \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "print(f'{stoi=}\\n{itos=}')\n",
    "print(len(words), 'words')\n",
    "print(len(xs), ' input letters ', xs[0:5])\n",
    "print(len(ys), 'labels', ys[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "1d633514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([228145])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e908978b0>"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nb_of_examples = -1\n",
    "\n",
    "inputs = xs[0:nb_of_examples]\n",
    "outputs = ys[0:nb_of_examples]\n",
    "print(inputs.shape)\n",
    "xenc = Fun.one_hot(inputs, num_classes=symbol_count).float()\n",
    "plt.imshow(xenc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "e3c73eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4.7940,  0.7888,  0.9730,  0.3326,  1.3309,  0.9708,  0.2129,  1.8311,\n",
       "           1.0824,  2.4710,  0.6242,  2.1964,  0.7200,  0.6486,  3.9469, 18.7908,\n",
       "           4.7673,  0.1967,  1.9683,  0.4315,  2.6775,  0.8621,  0.2277,  1.5656,\n",
       "           0.9317, 12.1434, 11.5281],\n",
       "         [ 1.6038,  4.4060,  1.3737,  2.8830, 11.0032,  1.5972,  0.5187,  1.8527,\n",
       "           0.5369,  1.6654,  3.8818,  1.2642,  0.6339,  0.9987,  0.5995,  1.7432,\n",
       "           1.6073,  0.2499,  5.0680,  1.1876,  2.6871,  1.6596,  2.7728,  0.1486,\n",
       "           0.6521,  0.1193,  2.6128],\n",
       "         [ 1.2136,  2.8669,  1.8850,  1.2942,  2.6224,  0.7799,  1.0251,  0.9701,\n",
       "           4.7691,  0.6386,  0.2910,  3.0710,  0.5098,  1.0386,  0.5719,  0.4373,\n",
       "           2.2763,  0.4719,  2.5289,  0.2265,  0.8082,  0.3054,  0.5164,  0.7918,\n",
       "           4.6866,  1.8232,  0.4921],\n",
       "         [ 1.2136,  2.8669,  1.8850,  1.2942,  2.6224,  0.7799,  1.0251,  0.9701,\n",
       "           4.7691,  0.6386,  0.2910,  3.0710,  0.5098,  1.0386,  0.5719,  0.4373,\n",
       "           2.2763,  0.4719,  2.5289,  0.2265,  0.8082,  0.3054,  0.5164,  0.7918,\n",
       "           4.6866,  1.8232,  0.4921],\n",
       "         [ 0.5117,  0.2953,  1.3541,  0.3422,  2.0701,  1.0524,  3.7043,  0.4483,\n",
       "           0.4272,  0.1642,  3.4984,  0.2936,  3.3753,  0.3811,  0.7929,  0.7064,\n",
       "           1.3944,  0.2655,  3.0723,  1.8156,  1.5816,  1.0555,  0.1755,  1.1225,\n",
       "           2.2327,  1.7179,  0.3120]], grad_fn=<ExpBackward0>),\n",
       " torch.Size([5, 27]),\n",
       " tensor([[79.0145],\n",
       "         [55.3268],\n",
       "         [38.9116],\n",
       "         [38.9116],\n",
       "         [34.1630]], grad_fn=<SumBackward1>))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = torch.manual_seed(2147483647)\n",
    "W = torch.randn((symbol_count, symbol_count), generator=g, requires_grad=True)\n",
    "\n",
    "x = inputs[:5]\n",
    "xenc = Fun.one_hot(x, num_classes=symbol_count).float()\n",
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "\n",
    "counts,counts.shape, counts.sum(1, keepdims=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e0d59fab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228145 inputs tensor([ 0,  5, 13,  ..., 26, 25, 26])\n",
      "228145 outputs tensor([ 5, 13, 13,  ..., 25, 26, 24])\n",
      "27\n",
      "0 loss: 3.305837392807007\n",
      "   0 .qvsaayxbqrqmyqwuznivanukotdjvdhd.\n",
      "   1 .qnoymtzduqkatdetkpfjdgigvlejfkrsqlwnirghhzwlu.\n",
      "   2 .idcx.\n",
      "   3 .cekmzucjnjoeovjvrggqrjr.\n",
      "   4 .cfbhabkslpokc.\n",
      "100 loss: 3.0796680450439453\n",
      "   0 .xtxwbpmjntusxdgzfexhwqpldpdnwzvjyxsqjforqqpfxstvkfoufhvwfhlruyynsvcvvqqfcbydibouhjaijhqnloqmmlkanqdqy.\n",
      "   1 .gszpw.\n",
      "   2 .zlfiiin.\n",
      "   3 .mgzzuulryuqrufuawausdamwvllqypvgrrefpshfmmwaeplricvbgnduojhfxhkwcltrdjwn.\n",
      "   4 .gzykmqv.\n",
      "200 loss: 2.937119483947754\n",
      "   0 .kersdqjgun.\n",
      "   1 .cojcdtstjfdo.\n",
      "   2 .adokrxeojbslhwguzer.\n",
      "   3 .voflejxflyle.\n",
      "   4 .dfpjcpntcsvablzyrptragxhabn.\n",
      "300 loss: 2.846243381500244\n",
      "   0 .guum.\n",
      "   1 .vtyqle.\n",
      "   2 .ka.\n",
      "   3 .ma.\n",
      "   4 .lyinihtukelar.\n",
      "400 loss: 2.7836146354675293\n",
      "   0 .sbqcftilizqta.\n",
      "   1 .gsuwrresnanifgwudciazsqopeienrsxmus.\n",
      "   2 .ikxencjozbh.\n",
      "   3 .rieahtjbicawcetkomsivvutxlylrvyjenzaruduxfubon.\n",
      "   4 .kbdoilgemjhaian.\n",
      "500 loss: 2.7381536960601807\n",
      "   0 .mus.\n",
      "   1 .avkwcjai.\n",
      "   2 .k.\n",
      "   3 .mstyejtmylyaph.\n",
      "   4 .jnkjhxrbrmplilana.\n",
      "600 loss: 2.704000473022461\n",
      "   0 .svpnamdsandojra.\n",
      "   1 .taysipmun.\n",
      "   2 .llvbdejmpeyunlyquffvhhmia.\n",
      "   3 .cjs.\n",
      "   4 .e.\n",
      "700 loss: 2.6775732040405273\n",
      "   0 .der.\n",
      "   1 .swpeelixqryayaswa.\n",
      "   2 .maiqnpelvdvowen.\n",
      "   3 .wtsstem.\n",
      "   4 .h.\n",
      "800 loss: 2.656576633453369\n",
      "   0 .r.\n",
      "   1 .nz.\n",
      "   2 .rxnenaxp.\n",
      "   3 .kybljjiyl.\n",
      "   4 .xmaamipellimtwicgtoe.\n",
      "900 loss: 2.6395092010498047\n",
      "   0 .ve.\n",
      "   1 .le.\n",
      "   2 .kya.\n",
      "   3 .kloma.\n",
      "   4 .ks.\n",
      "1000 loss: 2.6253671646118164\n",
      "   0 .voocrilelyna.\n",
      "   1 .b.\n",
      "   2 .ryargmaia.\n",
      "   3 .keekan.\n",
      "   4 .joranbelspwckairona.\n",
      "1100 loss: 2.6134583950042725\n",
      "   0 .jalicallochabwicynda.\n",
      "   1 .min.\n",
      "   2 .n.\n",
      "   3 .ekzamma.\n",
      "   4 .lcelelxque.\n",
      "1200 loss: 2.6032941341400146\n",
      "   0 .haborara.\n",
      "   1 .a.\n",
      "   2 .thleirecogfo.\n",
      "   3 .mieenxon.\n",
      "   4 .llhelesnmzxelarannkqza.\n",
      "1300 loss: 2.594517946243286\n",
      "   0 .dimirade.\n",
      "   1 .cenaqkcteesauazh.\n",
      "   2 .maha.\n",
      "   3 .dkfoptangeigha.\n",
      "   4 .vilan.\n",
      "1400 loss: 2.5868654251098633\n",
      "   0 .tvwpyaialndvhqqradari.\n",
      "   1 .ssi.\n",
      "   2 .beliayyan.\n",
      "   3 .maixxzekeio.\n",
      "   4 .arytpyienkzpgh.\n",
      "1500 loss: 2.5801334381103516\n",
      "   0 .kavkan.\n",
      "   1 .er.\n",
      "   2 .kawhazriwqjaspmca.\n",
      "   3 .dzanztigxtsdin.\n",
      "   4 .aqvavitran.\n",
      "1600 loss: 2.5741665363311768\n",
      "   0 .keen.\n",
      "   1 .arolovimymairfirosa.\n",
      "   2 .xyterf.\n",
      "   3 .ckan.\n",
      "   4 .jeeawe.\n",
      "1700 loss: 2.5688414573669434\n",
      "   0 .ma.\n",
      "   1 .gyyllgitmayla.\n",
      "   2 .oninuva.\n",
      "   3 .h.\n",
      "   4 .ave.\n",
      "1800 loss: 2.5640597343444824\n",
      "   0 .rxn.\n",
      "   1 .kxonafraricuxkayareumaqmayfbqdviracbiy.\n",
      "   2 .meehanen.\n",
      "   3 .larxtsh.\n",
      "   4 .ppssae.\n",
      "1900 loss: 2.559744119644165\n",
      "   0 .sgxve.\n",
      "   1 .esjareeyna.\n",
      "   2 .nialeygr.\n",
      "   3 .cpgzeynafmayfoann.\n",
      "   4 .jele.\n",
      "2000 loss: 2.555828809738159\n",
      "   0 .ronnn.\n",
      "   1 .n.\n",
      "   2 .jan.\n",
      "   3 .s.\n",
      "   4 .tpfsi.\n",
      "2100 loss: 2.5522611141204834\n",
      "   0 .d.\n",
      "   1 .aliojyramalele.\n",
      "   2 .bwybede.\n",
      "   3 .en.\n",
      "   4 .jkasiannha.\n",
      "2200 loss: 2.548997163772583\n",
      "   0 .kayarrieyle.\n",
      "   1 .storiertoniclish.\n",
      "   2 .in.\n",
      "   3 .a.\n",
      "   4 .atsimacly.\n",
      "2300 loss: 2.5460009574890137\n",
      "   0 .delat.\n",
      "   1 .janzzayse.\n",
      "   2 .xghlexmavdis.\n",
      "   3 .k.\n",
      "   4 .yn.\n",
      "2400 loss: 2.5432400703430176\n",
      "   0 .kseyleman.\n",
      "   1 .kayalin.\n",
      "   2 .miriauha.\n",
      "   3 .kra.\n",
      "   4 .zv.\n",
      "2500 loss: 2.5406885147094727\n",
      "   0 .ah.\n",
      "   1 .eraklst.\n",
      "   2 .anan.\n",
      "   3 .jan.\n",
      "   4 .rel.\n",
      "2600 loss: 2.5383245944976807\n",
      "   0 .ch.\n",
      "   1 .ka.\n",
      "   2 .vteeenamasjollleloninnesynti.\n",
      "   3 .damei.\n",
      "   4 .saugecxbeiqfbinezaliayadn.\n",
      "2700 loss: 2.536127805709839\n",
      "   0 .naze.\n",
      "   1 .ka.\n",
      "   2 .tluur.\n",
      "   3 .meyanaseicjerdon.\n",
      "   4 .ckajaynn.\n",
      "2800 loss: 2.5340819358825684\n",
      "   0 .ara.\n",
      "   1 .so.\n",
      "   2 .rs.\n",
      "   3 .rugh.\n",
      "   4 .dr.\n",
      "2900 loss: 2.532172441482544\n",
      "   0 .ydaadovily.\n",
      "   1 .kkaliahariafn.\n",
      "   2 .analewa.\n",
      "   3 .laynpeme.\n",
      "   4 .qglha.\n",
      "3000 loss: 2.530386209487915\n",
      "   0 .swtlell.\n",
      "   1 .rer.\n",
      "   2 .jan.\n",
      "   3 .orie.\n",
      "   4 .t.\n",
      "3100 loss: 2.5287117958068848\n",
      "   0 .qsy.\n",
      "   1 .kevidistandykananiken.\n",
      "   2 .cema.\n",
      "   3 .cachyanishwelielimoan.\n",
      "   4 .bwha.\n",
      "3200 loss: 2.5271401405334473\n",
      "   0 .macutk.\n",
      "   1 .ibillan.\n",
      "   2 .hmme.\n",
      "   3 .keimtofudzan.\n",
      "   4 .jalake.\n",
      "3300 loss: 2.5256614685058594\n",
      "   0 .uthheyanga.\n",
      "   1 .ckash.\n",
      "   2 .ty.\n",
      "   3 .mian.\n",
      "   4 .kp.\n",
      "3400 loss: 2.5242691040039062\n",
      "   0 .rwikanah.\n",
      "   1 .hke.\n",
      "   2 .yakrierericrunnoscante.\n",
      "   3 .n.\n",
      "   4 .l.\n",
      "3500 loss: 2.5229547023773193\n",
      "   0 .jiahafebee.\n",
      "   1 .e.\n",
      "   2 .ry.\n",
      "   3 .a.\n",
      "   4 .krbigfmmjochayaronanna.\n",
      "3600 loss: 2.5217127799987793\n",
      "   0 .lizswpzhe.\n",
      "   1 .jayala.\n",
      "   2 .auwi.\n",
      "   3 .kha.\n",
      "   4 .kameer.\n",
      "3700 loss: 2.520538091659546\n",
      "   0 .ry.\n",
      "   1 .anindrmatofbhsaindorie.\n",
      "   2 .shaliamawfvmabxligandemya.\n",
      "   3 .bkercay.\n",
      "   4 .sene.\n",
      "3800 loss: 2.5194246768951416\n",
      "   0 .seren.\n",
      "   1 .reradn.\n",
      "   2 .ekan.\n",
      "   3 .pka.\n",
      "   4 .amaylaneli.\n",
      "3900 loss: 2.518368721008301\n",
      "   0 .tayiastopjajan.\n",
      "   1 .te.\n",
      "   2 .nndbr.\n",
      "   3 .am.\n",
      "   4 .sehrecheytiah.\n",
      "4000 loss: 2.5173656940460205\n",
      "   0 .soxpethiymi.\n",
      "   1 .cahdonn.\n",
      "   2 .kkysria.\n",
      "   3 .jam.\n",
      "   4 .kleik.\n",
      "4100 loss: 2.516411542892456\n",
      "   0 .taqgi.\n",
      "   1 .kianel.\n",
      "   2 .t.\n",
      "   3 .a.\n",
      "   4 .xayne.\n",
      "4200 loss: 2.5155038833618164\n",
      "   0 .caha.\n",
      "   1 .nanytolemon.\n",
      "   2 .ve.\n",
      "   3 .avganeeyaynayne.\n",
      "   4 .cel.\n",
      "4300 loss: 2.514638662338257\n",
      "   0 .ca.\n",
      "   1 .xitoeflielexpxgo.\n",
      "   2 .da.\n",
      "   3 .evorlllanaheshia.\n",
      "   4 .zeofledeikwn.\n",
      "4400 loss: 2.5138137340545654\n",
      "   0 .rusrinezexisnn.\n",
      "   1 .ck.\n",
      "   2 .jarereioxha.\n",
      "   3 .lianadfamhairanilevinasai.\n",
      "   4 .jsoh.\n",
      "4500 loss: 2.5130255222320557\n",
      "   0 .tstzeririrayasqela.\n",
      "   1 .etzevjan.\n",
      "   2 .mwha.\n",
      "   3 .wcee.\n",
      "   4 .h.\n",
      "4600 loss: 2.512272834777832\n",
      "   0 .ee.\n",
      "   1 .dadeie.\n",
      "   2 .e.\n",
      "   3 .nn.\n",
      "   4 .minyaitelyavannanahan.\n",
      "4700 loss: 2.511552333831787\n",
      "   0 .zitha.\n",
      "   1 .xdilimima.\n",
      "   2 .brnnak.\n",
      "   3 .lyqmasonc.\n",
      "   4 .au.\n",
      "4800 loss: 2.5108630657196045\n",
      "   0 .h.\n",
      "   1 .mon.\n",
      "   2 .sangarenonjuzinn.\n",
      "   3 .relontinn.\n",
      "   4 .kevrsigrtedaytakmienaidpwzravemwzeanjujendevit.\n",
      "4900 loss: 2.510202646255493\n",
      "   0 .kbbfaiey.\n",
      "   1 .ma.\n",
      "   2 .phied.\n",
      "   3 .rawyam.\n",
      "   4 .chaka.\n",
      "5000 loss: 2.509568929672241\n",
      "   0 .vacr.\n",
      "   1 .a.\n",
      "   2 .lyraicha.\n",
      "   3 .kis.\n",
      "   4 .ke.\n",
      "5100 loss: 2.5089614391326904\n",
      "   0 .zmwwme.\n",
      "   1 .vvilidatodeliaiqerkasonikiyon.\n",
      "   2 .alabrlllieemneh.\n",
      "   3 .ossaer.\n",
      "   4 .tb.\n",
      "5200 loss: 2.5083773136138916\n",
      "   0 .a.\n",
      "   1 .gavara.\n",
      "   2 .beys.\n",
      "   3 .ceemenave.\n",
      "   4 .drayrelesaf.\n",
      "5300 loss: 2.5078163146972656\n",
      "   0 .sta.\n",
      "   1 .to.\n",
      "   2 .rlynshatayntharuklle.\n",
      "   3 .e.\n",
      "   4 .nngh.\n",
      "5400 loss: 2.507276773452759\n",
      "   0 .iztola.\n",
      "   1 .zlings.\n",
      "   2 .briayosselulenilylyre.\n",
      "   3 .na.\n",
      "   4 .a.\n",
      "5500 loss: 2.506757974624634\n",
      "   0 .a.\n",
      "   1 .a.\n",
      "   2 .k.\n",
      "   3 .ko.\n",
      "   4 .kalelerinailadabali.\n",
      "5600 loss: 2.506258010864258\n",
      "   0 .amzeeyri.\n",
      "   1 .tam.\n",
      "   2 .munno.\n",
      "   3 .mayn.\n",
      "   4 .dann.\n",
      "5700 loss: 2.5057764053344727\n",
      "   0 .jamaja.\n",
      "   1 ..\n",
      "   2 .jevynikiaevbpfon.\n",
      "   3 .ainiobonprigquugivi.\n",
      "   4 .ah.\n",
      "5800 loss: 2.505312204360962\n",
      "   0 .somiademian.\n",
      "   1 .acx.\n",
      "   2 .jaillshe.\n",
      "   3 .dabfoswn.\n",
      "   4 .ge.\n",
      "5900 loss: 2.504863977432251\n",
      "   0 .ee.\n",
      "   1 .ono.\n",
      "   2 .ndendedileexgxjabe.\n",
      "   3 .rin.\n",
      "   4 .kalebre.\n",
      "6000 loss: 2.50443172454834\n",
      "   0 .shyne.\n",
      "   1 .anthamaliakouyn.\n",
      "   2 .amei.\n",
      "   3 .alayata.\n",
      "   4 .merile.\n",
      "6100 loss: 2.504014730453491\n",
      "   0 .a.\n",
      "   1 .bmjonynen.\n",
      "   2 .juhjan.\n",
      "   3 .karaderai.\n",
      "   4 .cquharai.\n",
      "6200 loss: 2.5036110877990723\n",
      "   0 .aniay.\n",
      "   1 .ja.\n",
      "   2 .wei.\n",
      "   3 .vh.\n",
      "   4 .arvi.\n",
      "6300 loss: 2.503221273422241\n",
      "   0 .an.\n",
      "   1 .ge.\n",
      "   2 .kveah.\n",
      "   3 .malarthakeflie.\n",
      "   4 .mte.\n",
      "6400 loss: 2.5028438568115234\n",
      "   0 .kar.\n",
      "   1 .arreighal.\n",
      "   2 .r.\n",
      "   3 .maan.\n",
      "   4 .us.\n",
      "6500 loss: 2.502479076385498\n",
      "   0 .tarvenaenizanzan.\n",
      "   1 .totemitidayliaxj.\n",
      "   2 .d.\n",
      "   3 .jarepanammanah.\n",
      "   4 .las.\n",
      "6600 loss: 2.5021255016326904\n",
      "   0 .al.\n",
      "   1 .cge.\n",
      "   2 .rqosan.\n",
      "   3 .misiclih.\n",
      "   4 .kya.\n",
      "6700 loss: 2.501783609390259\n",
      "   0 .rion.\n",
      "   1 .mabi.\n",
      "   2 .arnilel.\n",
      "   3 .kar.\n",
      "   4 .chabdyiy.\n",
      "6800 loss: 2.5014517307281494\n",
      "   0 .haioocanannydrowaiayn.\n",
      "   1 .lymaniemah.\n",
      "   2 .jon.\n",
      "   3 .zr.\n",
      "   4 .kennyn.\n",
      "6900 loss: 2.5011303424835205\n",
      "   0 .bava.\n",
      "   1 .an.\n",
      "   2 .ma.\n",
      "   3 .lidandaevedisa.\n",
      "   4 .anduenneyleleleiaioea.\n",
      "7000 loss: 2.5008184909820557\n",
      "   0 .bonaysan.\n",
      "   1 .amfrle.\n",
      "   2 .b.\n",
      "   3 .deilare.\n",
      "   4 .k.\n",
      "7100 loss: 2.500516176223755\n",
      "   0 .r.\n",
      "   1 .jeta.\n",
      "   2 .tarsray.\n",
      "   3 .cvihamfbaronie.\n",
      "   4 .khismaiczmcora.\n",
      "7200 loss: 2.500222682952881\n",
      "   0 .regili.\n",
      "   1 .areelorwmiorozeeli.\n",
      "   2 .kelidokelilqvini.\n",
      "   3 .ky.\n",
      "   4 .degn.\n",
      "7300 loss: 2.4999377727508545\n",
      "   0 .enammai.\n",
      "   1 .jeeumiasssuzaee.\n",
      "   2 .ayn.\n",
      "   3 .aenalen.\n",
      "   4 .ahore.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7400 loss: 2.4996604919433594\n",
      "   0 .kxwaarere.\n",
      "   1 .zwdraloneryah.\n",
      "   2 .jzicum.\n",
      "   3 .n.\n",
      "   4 .komee.\n",
      "7500 loss: 2.499391794204712\n",
      "   0 .movavgolen.\n",
      "   1 .slivylelilirellla.\n",
      "   2 .leadikabr.\n",
      "   3 .hx.\n",
      "   4 .eroneh.\n",
      "7600 loss: 2.4991300106048584\n",
      "   0 .eli.\n",
      "   1 .ka.\n",
      "   2 .kanaima.\n",
      "   3 .jhepron.\n",
      "   4 .elouweist.\n",
      "7700 loss: 2.498875856399536\n",
      "   0 .a.\n",
      "   1 .jos.\n",
      "   2 .sil.\n",
      "   3 .hayced.\n",
      "   4 .zelor.\n",
      "7800 loss: 2.498628616333008\n",
      "   0 .yyjare.\n",
      "   1 .n.\n",
      "   2 .plee.\n",
      "   3 .yltasarra.\n",
      "   4 .pe.\n",
      "7900 loss: 2.4983878135681152\n",
      "   0 .enn.\n",
      "   1 .kerahason.\n",
      "   2 .kauzffuralimil.\n",
      "   3 .n.\n",
      "   4 .an.\n",
      "8000 loss: 2.4981536865234375\n",
      "   0 .aayona.\n",
      "   1 .s.\n",
      "   2 .melymatra.\n",
      "   3 .masugh.\n",
      "   4 .cptays.\n",
      "8100 loss: 2.4979255199432373\n",
      "   0 .ph.\n",
      "   1 .dann.\n",
      "   2 .keneha.\n",
      "   3 .jqkel.\n",
      "   4 .rr.\n",
      "8200 loss: 2.497703790664673\n",
      "   0 .e.\n",
      "   1 .f.\n",
      "   2 .rigwn.\n",
      "   3 .hbry.\n",
      "   4 .wallla.\n",
      "8300 loss: 2.4974870681762695\n",
      "   0 .m.\n",
      "   1 .za.\n",
      "   2 .s.\n",
      "   3 .faelamowyayquxstyaresten.\n",
      "   4 .a.\n",
      "8400 loss: 2.4972760677337646\n",
      "   0 .mandar.\n",
      "   1 .he.\n",
      "   2 .kaida.\n",
      "   3 .deeniasa.\n",
      "   4 .fjesal.\n",
      "8500 loss: 2.497070550918579\n",
      "   0 .rr.\n",
      "   1 .deo.\n",
      "   2 .gcaebemen.\n",
      "   3 .keeseniah.\n",
      "   4 .me.\n",
      "8600 loss: 2.496870279312134\n",
      "   0 .emironare.\n",
      "   1 .ry.\n",
      "   2 .kabrwbolil.\n",
      "   3 .s.\n",
      "   4 .accka.\n",
      "8700 loss: 2.4966750144958496\n",
      "   0 .kan.\n",
      "   1 .dqvalelon.\n",
      "   2 .fisa.\n",
      "   3 .ja.\n",
      "   4 .r.\n",
      "8800 loss: 2.4964842796325684\n",
      "   0 .justamalitkher.\n",
      "   1 .h.\n",
      "   2 .sh.\n",
      "   3 .ll.\n",
      "   4 .gaymqbxaxxan.\n",
      "8900 loss: 2.49629807472229\n",
      "   0 .eeliatiylasbann.\n",
      "   1 .jdrhk.\n",
      "   2 .mayeystur.\n",
      "   3 .akaen.\n",
      "   4 .amitorimahy.\n",
      "9000 loss: 2.4961163997650146\n",
      "   0 .susaiti.\n",
      "   1 .ri.\n",
      "   2 .ghxezai.\n",
      "   3 .teri.\n",
      "   4 .jerylemovtsbrquleri.\n",
      "9100 loss: 2.495938777923584\n",
      "   0 .deliaharchbelle.\n",
      "   1 .rie.\n",
      "   2 .ahasah.\n",
      "   3 .kymaveralannwana.\n",
      "   4 .briiaizer.\n",
      "9200 loss: 2.4957656860351562\n",
      "   0 .k.\n",
      "   1 .taiceresala.\n",
      "   2 .azweckennama.\n",
      "   3 .heqtlnon.\n",
      "   4 .da.\n",
      "9300 loss: 2.495596408843994\n",
      "   0 .th.\n",
      "   1 .emalzaienamama.\n",
      "   2 .karsandegaya.\n",
      "   3 .kadaloritonan.\n",
      "   4 .n.\n",
      "9400 loss: 2.4954311847686768\n",
      "   0 .s.\n",
      "   1 .ch.\n",
      "   2 .ja.\n",
      "   3 .jon.\n",
      "   4 .cseacavzaygvan.\n",
      "9500 loss: 2.495269775390625\n",
      "   0 .jan.\n",
      "   1 .leidahahey.\n",
      "   2 .riyaiylla.\n",
      "   3 .xiggonambelvah.\n",
      "   4 .lli.\n",
      "9600 loss: 2.4951117038726807\n",
      "   0 .maha.\n",
      "   1 .seacelamivania.\n",
      "   2 .lydy.\n",
      "   3 .cedoh.\n",
      "   4 .errianamm.\n",
      "9700 loss: 2.494957208633423\n",
      "   0 .m.\n",
      "   1 .metr.\n",
      "   2 .xia.\n",
      "   3 .kruiy.\n",
      "   4 .kradi.\n",
      "9800 loss: 2.4948062896728516\n",
      "   0 .melanoruliris.\n",
      "   1 .kupe.\n",
      "   2 .be.\n",
      "   3 .eyanoomie.\n",
      "   4 .lin.\n",
      "9900 loss: 2.4946582317352295\n",
      "   0 .noobrontaunn.\n",
      "   1 .dakenn.\n",
      "   2 .lylelya.\n",
      "   3 .an.\n",
      "   4 .rizuexshtratyon.\n",
      "0 .mor.\n",
      "1 .axx.\n",
      "2 .minaymoryles.\n",
      "3 .kondmaisah.\n",
      "4 .anchthizarie.\n",
      "5 .odaren.\n",
      "6 .iaddash.\n",
      "7 .h.\n",
      "8 .jionatien.\n",
      "9 .egxwer.\n"
     ]
    }
   ],
   "source": [
    "g = torch.manual_seed(2147483647)\n",
    "\n",
    "def word_gen(W):\n",
    "    word = ''\n",
    "    next_char = '.'\n",
    "    while True:\n",
    "        # print(f'{next_char=}')\n",
    "        word += next_char\n",
    "        xenc = Fun.one_hot(torch.tensor([stoi[next_char]]), num_classes=symbol_count).float()\n",
    "        logits = xenc @ W\n",
    "        # softmax our outputs into a probability distribution\n",
    "        counts = logits.exp()\n",
    "        probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "        # print(probs)\n",
    "        next_char = itos[torch.multinomial(probs, 1, replacement=True, generator=g).item()]\n",
    "        if next_char == '.':\n",
    "            word += '.'\n",
    "            break\n",
    "        \n",
    "    return word\n",
    "\n",
    "\n",
    "def optimize(inputs, labels, w_adjust, passes):   \n",
    "    # W = torch.randn((symbol_count, symbol_count), generator=g, requires_grad=True)\n",
    "    W = torch.ones((symbol_count, symbol_count), requires_grad=True)\n",
    "    # print(inputs, labels, w_adjust, passes)\n",
    "    for i in range(passes):\n",
    "        # forward\n",
    "        xenc = Fun.one_hot(inputs, num_classes=symbol_count).float()\n",
    "        logits = xenc @ W\n",
    "        # softmax our outputs into a probability distribution\n",
    "        counts = logits.exp()\n",
    "       \n",
    "        probs = counts / counts.sum(dim=1, keepdims=True)\n",
    "        # print(probs)\n",
    "        # print(torch.arange(len(inputs)))\n",
    "        # backwards\n",
    "        # 0.01 * (W**2).mean() is the regularization\n",
    "        loss = -probs[torch.arange(len(inputs)), labels].log().mean() + 0.01 * (W**2).mean()\n",
    "        if i % 100 == 0:\n",
    "            print(i, 'loss:', loss.item())\n",
    "            for i in range(5):\n",
    "                w = word_gen(W)\n",
    "                print('  ',i, w)\n",
    "        W.grad = None\n",
    "        loss.backward()\n",
    "        # update\n",
    "        W.data += -w_adjust * W.grad\n",
    "    return W\n",
    "\n",
    "\n",
    "print(len(inputs), 'inputs', inputs)\n",
    "print(len(outputs), 'outputs', outputs)\n",
    "print(symbol_count)\n",
    "weights = optimize(inputs, outputs, 0.5, 10000)\n",
    "g = torch.manual_seed(2147483647)\n",
    "for i in range(10):\n",
    "    w = word_gen(weights)\n",
    "    print(i, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6166c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
